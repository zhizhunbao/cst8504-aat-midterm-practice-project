{
  "dataframes-series": {
    "zh": {
      "concepts": [
        "Pandas是Python中用于数据分析和处理的核心库",
        "DataFrame是Pandas的主要数据结构，类似于Excel表格",
        "Series是一维数组，可以看作是DataFrame的一列",
        "Pandas提供了强大的数据读取、清洗、转换和分析功能",
        "Pandas支持多种数据格式的导入导出（CSV、Excel、JSON等）",
        "Series和DataFrames是期中考试的重点内容"
      ],
      "examples": [
        {
          "title": "创建DataFrame和Series",
          "code": "import pandas as pd\nimport numpy as np\n\n# 从字典创建DataFrame\ndata = {\n    '姓名': ['张三', '李四', '王五', '赵六'],\n    '年龄': [25, 30, 35, 28],\n    '城市': ['北京', '上海', '广州', '深圳'],\n    '工资': [8000, 12000, 15000, 10000]\n}\ndf = pd.DataFrame(data)\nprint(df)\n\n# 创建Series\nages = pd.Series([25, 30, 35, 28], name='年龄')\nprint(ages)\n\n# 从列表创建DataFrame\nnames = ['张三', '李四', '王五']\nages = [25, 30, 35]\ndf2 = pd.DataFrame({'姓名': names, '年龄': ages})\nprint(df2)\n\n# 查看DataFrame基本信息\nprint(f\"形状: {df.shape}\")  # (4, 4)\nprint(f\"列名: {df.columns.tolist()}\")\nprint(f\"数据类型:\")\nprint(df.dtypes)"
        },
        {
          "title": "数据读取和保存",
          "code": "import pandas as pd\n\n# 读取CSV文件\n# df = pd.read_csv('data.csv')\n\n# 读取Excel文件\n# df = pd.read_excel('data.xlsx')\n\n# 读取JSON文件\n# df = pd.read_json('data.json')\n\n# 创建示例数据\ndata = {\n    '产品': ['手机', '电脑', '平板', '耳机'],\n    '价格': [3000, 8000, 4000, 500],\n    '库存': [100, 50, 80, 200]\n}\ndf = pd.DataFrame(data)\n\n# 保存为不同格式\n# df.to_csv('products.csv', index=False)\n# df.to_excel('products.xlsx', index=False)\n# df.to_json('products.json', orient='records')\n\nprint(\"DataFrame内容:\")\nprint(df)\nprint(\"\\n前3行:\")\nprint(df.head(3))\nprint(\"\\n后2行:\")\nprint(df.tail(2))"
        },
        {
          "title": "数据选择和过滤",
          "code": "import pandas as pd\n\n# 创建示例数据\ndata = {\n    '姓名': ['张三', '李四', '王五', '赵六', '孙七'],\n    '年龄': [25, 30, 35, 28, 32],\n    '部门': ['技术', '销售', '技术', '人事', '销售'],\n    '工资': [8000, 12000, 15000, 10000, 11000]\n}\ndf = pd.DataFrame(data)\nprint(\"原始数据:\")\nprint(df)\n\n# 选择列\nprint(\"\\n选择单列:\")\nprint(df['姓名'])\nprint(\"\\n选择多列:\")\nprint(df[['姓名', '工资']])\n\n# 选择行\nprint(\"\\n选择前3行:\")\nprint(df.iloc[0:3])\nprint(\"\\n选择特定行:\")\nprint(df.iloc[[0, 2, 4]])\n\n# 条件过滤\nprint(\"\\n工资大于10000的员工:\")\nhigh_salary = df[df['工资'] > 10000]\nprint(high_salary)\n\nprint(\"\\n技术部门的员工:\")\ntech_dept = df[df['部门'] == '技术']\nprint(tech_dept)\n\n# 复合条件\nprint(\"\\n年龄大于25且工资大于10000的员工:\")\ncondition = (df['年龄'] > 25) & (df['工资'] > 10000)\nfiltered = df[condition]\nprint(filtered)"
        }
      ],
      "keyPoints": [
        "使用pd.DataFrame()创建数据框，pd.Series()创建序列",
        "使用方括号[]选择列，iloc[]按位置选择行",
        "布尔索引用于条件过滤，支持复合条件",
        "head()和tail()方法查看数据的前几行和后几行",
        "shape属性获取数据框的维度信息"
      ]
    },
    "en": {
      "concepts": [
        "Pandas is the core library for data analysis and manipulation in Python",
        "DataFrame is Pandas' main data structure, similar to Excel spreadsheets",
        "Series is a one-dimensional array, can be seen as a column of DataFrame",
        "Pandas provides powerful data reading, cleaning, transformation and analysis functions",
        "Pandas supports import/export of multiple data formats (CSV, Excel, JSON, etc.)"
      ],
      "examples": [
        {
          "title": "Creating DataFrame and Series",
          "code": "import pandas as pd\nimport numpy as np\n\n# Create DataFrame from dictionary\ndata = {\n    'Name': ['John', 'Jane', 'Bob', 'Alice'],\n    'Age': [25, 30, 35, 28],\n    'City': ['New York', 'London', 'Tokyo', 'Paris'],\n    'Salary': [8000, 12000, 15000, 10000]\n}\ndf = pd.DataFrame(data)\nprint(df)\n\n# Create Series\nages = pd.Series([25, 30, 35, 28], name='Age')\nprint(ages)\n\n# Create DataFrame from lists\nnames = ['John', 'Jane', 'Bob']\nages = [25, 30, 35]\ndf2 = pd.DataFrame({'Name': names, 'Age': ages})\nprint(df2)\n\n# View DataFrame basic info\nprint(f\"Shape: {df.shape}\")  # (4, 4)\nprint(f\"Columns: {df.columns.tolist()}\")\nprint(f\"Data types:\")\nprint(df.dtypes)"
        },
        {
          "title": "Data Reading and Saving",
          "code": "import pandas as pd\n\n# Read CSV file\n# df = pd.read_csv('data.csv')\n\n# Read Excel file\n# df = pd.read_excel('data.xlsx')\n\n# Read JSON file\n# df = pd.read_json('data.json')\n\n# Create sample data\ndata = {\n    'Product': ['Phone', 'Computer', 'Tablet', 'Headphones'],\n    'Price': [3000, 8000, 4000, 500],\n    'Stock': [100, 50, 80, 200]\n}\ndf = pd.DataFrame(data)\n\n# Save in different formats\n# df.to_csv('products.csv', index=False)\n# df.to_excel('products.xlsx', index=False)\n# df.to_json('products.json', orient='records')\n\nprint(\"DataFrame content:\")\nprint(df)\nprint(\"\\nFirst 3 rows:\")\nprint(df.head(3))\nprint(\"\\nLast 2 rows:\")\nprint(df.tail(2))"
        },
        {
          "title": "Data Selection and Filtering",
          "code": "import pandas as pd\n\n# Create sample data\ndata = {\n    'Name': ['John', 'Jane', 'Bob', 'Alice', 'Charlie'],\n    'Age': [25, 30, 35, 28, 32],\n    'Department': ['IT', 'Sales', 'IT', 'HR', 'Sales'],\n    'Salary': [8000, 12000, 15000, 10000, 11000]\n}\ndf = pd.DataFrame(data)\nprint(\"Original data:\")\nprint(df)\n\n# Select columns\nprint(\"\\nSelect single column:\")\nprint(df['Name'])\nprint(\"\\nSelect multiple columns:\")\nprint(df[['Name', 'Salary']])\n\n# Select rows\nprint(\"\\nSelect first 3 rows:\")\nprint(df.iloc[0:3])\nprint(\"\\nSelect specific rows:\")\nprint(df.iloc[[0, 2, 4]])\n\n# Conditional filtering\nprint(\"\\nEmployees with salary > 10000:\")\nhigh_salary = df[df['Salary'] > 10000]\nprint(high_salary)\n\nprint(\"\\nIT department employees:\")\nit_dept = df[df['Department'] == 'IT']\nprint(it_dept)\n\n# Compound conditions\nprint(\"\\nEmployees age > 25 and salary > 10000:\")\ncondition = (df['Age'] > 25) & (df['Salary'] > 10000)\nfiltered = df[condition]\nprint(filtered)"
        }
      ],
      "keyPoints": [
        "Use pd.DataFrame() to create dataframes, pd.Series() to create series",
        "Use square brackets [] to select columns, iloc[] to select rows by position",
        "Boolean indexing for conditional filtering, supports compound conditions",
        "head() and tail() methods to view first and last rows",
        "shape attribute to get dataframe dimensions"
      ]
    }
  },
  "data-manipulation": {
    "zh": {
      "concepts": [
        "数据清洗是数据分析的重要步骤，包括处理缺失值、重复值等",
        "Pandas提供了丰富的数据转换和重塑功能",
        "分组操作(groupby)是数据分析的核心功能",
        "数据合并和连接操作可以组合多个数据集",
        "时间序列处理是Pandas的强项之一"
      ],
      "examples": [
        {
          "title": "数据清洗",
          "code": "import pandas as pd\nimport numpy as np\n\n# 创建包含缺失值的数据\ndata = {\n    '姓名': ['张三', '李四', None, '王五', '赵六'],\n    '年龄': [25, 30, np.nan, 35, 28],\n    '工资': [8000, 12000, 15000, None, 10000],\n    '部门': ['技术', '销售', '技术', '人事', '销售']\n}\ndf = pd.DataFrame(data)\nprint(\"原始数据:\")\nprint(df)\n\n# 检查缺失值\nprint(\"\\n缺失值统计:\")\nprint(df.isnull().sum())\n\n# 删除包含缺失值的行\ndf_dropna = df.dropna()\nprint(\"\\n删除缺失值后:\")\nprint(df_dropna)\n\n# 填充缺失值\ndf_filled = df.fillna({\n    '姓名': '未知',\n    '年龄': df['年龄'].mean(),\n    '工资': df['工资'].median()\n})\nprint(\"\\n填充缺失值后:\")\nprint(df_filled)\n\n# 删除重复行\ndf_no_duplicates = df.drop_duplicates()\nprint(\"\\n删除重复行后:\")\nprint(df_no_duplicates)"
        },
        {
          "title": "数据分组和聚合",
          "code": "import pandas as pd\n\n# 创建销售数据\ndata = {\n    '销售员': ['张三', '李四', '张三', '王五', '李四', '王五'],\n    '产品': ['手机', '电脑', '平板', '手机', '电脑', '平板'],\n    '销售额': [10000, 15000, 8000, 12000, 18000, 9000],\n    '月份': ['1月', '1月', '2月', '2月', '3月', '3月']\n}\ndf = pd.DataFrame(data)\nprint(\"销售数据:\")\nprint(df)\n\n# 按销售员分组\nprint(\"\\n按销售员分组统计:\")\nsales_by_person = df.groupby('销售员')['销售额'].sum()\nprint(sales_by_person)\n\n# 按产品分组\nprint(\"\\n按产品分组统计:\")\nproduct_stats = df.groupby('产品')['销售额'].agg(['sum', 'mean', 'count'])\nprint(product_stats)\n\n# 多级分组\nprint(\"\\n按销售员和产品分组:\")\nmulti_group = df.groupby(['销售员', '产品'])['销售额'].sum()\nprint(multi_group)\n\n# 透视表\nprint(\"\\n透视表:\")\npivot_table = df.pivot_table(\n    values='销售额',\n    index='销售员',\n    columns='产品',\n    aggfunc='sum',\n    fill_value=0\n)\nprint(pivot_table)"
        },
        {
          "title": "数据合并",
          "code": "import pandas as pd\n\n# 创建员工基本信息\ndf1 = pd.DataFrame({\n    '员工ID': [1, 2, 3, 4],\n    '姓名': ['张三', '李四', '王五', '赵六'],\n    '部门': ['技术', '销售', '技术', '人事']\n})\n\n# 创建员工薪资信息\ndf2 = pd.DataFrame({\n    '员工ID': [1, 2, 3, 5],\n    '工资': [8000, 12000, 15000, 10000],\n    '奖金': [1000, 2000, 3000, 1500]\n})\n\nprint(\"员工基本信息:\")\nprint(df1)\nprint(\"\\n员工薪资信息:\")\nprint(df2)\n\n# 内连接\nprint(\"\\n内连接结果:\")\ninner_join = pd.merge(df1, df2, on='员工ID', how='inner')\nprint(inner_join)\n\n# 左连接\nprint(\"\\n左连接结果:\")\nleft_join = pd.merge(df1, df2, on='员工ID', how='left')\nprint(left_join)\n\n# 外连接\nprint(\"\\n外连接结果:\")\nouter_join = pd.merge(df1, df2, on='员工ID', how='outer')\nprint(outer_join)\n\n# 按索引连接\ndf3 = pd.DataFrame({\n    'A': [1, 2, 3],\n    'B': [4, 5, 6]\n}, index=['a', 'b', 'c'])\n\ndf4 = pd.DataFrame({\n    'C': [7, 8, 9],\n    'D': [10, 11, 12]\n}, index=['a', 'b', 'd'])\n\nprint(\"\\n按索引连接:\")\nindex_join = pd.concat([df3, df4], axis=1)\nprint(index_join)"
        }
      ],
      "keyPoints": [
        "使用dropna()删除缺失值，fillna()填充缺失值",
        "groupby()进行分组操作，支持多级分组",
        "pivot_table()创建透视表，便于数据分析",
        "merge()合并数据框，支持多种连接方式",
        "concat()按行或列连接数据框"
      ]
    },
    "en": {
      "concepts": [
        "Data cleaning is an important step in data analysis, including handling missing values, duplicates, etc.",
        "Pandas provides rich data transformation and reshaping functions",
        "Group operations (groupby) are core functionality for data analysis",
        "Data merging and joining operations can combine multiple datasets",
        "Time series processing is one of Pandas' strengths"
      ],
      "examples": [
        {
          "title": "Data Cleaning",
          "code": "import pandas as pd\nimport numpy as np\n\n# Create data with missing values\ndata = {\n    'Name': ['John', 'Jane', None, 'Bob', 'Alice'],\n    'Age': [25, 30, np.nan, 35, 28],\n    'Salary': [8000, 12000, 15000, None, 10000],\n    'Department': ['IT', 'Sales', 'IT', 'HR', 'Sales']\n}\ndf = pd.DataFrame(data)\nprint(\"Original data:\")\nprint(df)\n\n# Check missing values\nprint(\"\\nMissing values count:\")\nprint(df.isnull().sum())\n\n# Drop rows with missing values\ndf_dropna = df.dropna()\nprint(\"\\nAfter dropping missing values:\")\nprint(df_dropna)\n\n# Fill missing values\ndf_filled = df.fillna({\n    'Name': 'Unknown',\n    'Age': df['Age'].mean(),\n    'Salary': df['Salary'].median()\n})\nprint(\"\\nAfter filling missing values:\")\nprint(df_filled)\n\n# Remove duplicate rows\ndf_no_duplicates = df.drop_duplicates()\nprint(\"\\nAfter removing duplicates:\")\nprint(df_no_duplicates)"
        },
        {
          "title": "Data Grouping and Aggregation",
          "code": "import pandas as pd\n\n# Create sales data\ndata = {\n    'Salesperson': ['John', 'Jane', 'John', 'Bob', 'Jane', 'Bob'],\n    'Product': ['Phone', 'Computer', 'Tablet', 'Phone', 'Computer', 'Tablet'],\n    'Sales': [10000, 15000, 8000, 12000, 18000, 9000],\n    'Month': ['Jan', 'Jan', 'Feb', 'Feb', 'Mar', 'Mar']\n}\ndf = pd.DataFrame(data)\nprint(\"Sales data:\")\nprint(df)\n\n# Group by salesperson\nprint(\"\\nGroup by salesperson:\")\nsales_by_person = df.groupby('Salesperson')['Sales'].sum()\nprint(sales_by_person)\n\n# Group by product\nprint(\"\\nGroup by product:\")\nproduct_stats = df.groupby('Product')['Sales'].agg(['sum', 'mean', 'count'])\nprint(product_stats)\n\n# Multi-level grouping\nprint(\"\\nGroup by salesperson and product:\")\nmulti_group = df.groupby(['Salesperson', 'Product'])['Sales'].sum()\nprint(multi_group)\n\n# Pivot table\nprint(\"\\nPivot table:\")\npivot_table = df.pivot_table(\n    values='Sales',\n    index='Salesperson',\n    columns='Product',\n    aggfunc='sum',\n    fill_value=0\n)\nprint(pivot_table)"
        },
        {
          "title": "Data Merging",
          "code": "import pandas as pd\n\n# Create employee basic info\ndf1 = pd.DataFrame({\n    'EmployeeID': [1, 2, 3, 4],\n    'Name': ['John', 'Jane', 'Bob', 'Alice'],\n    'Department': ['IT', 'Sales', 'IT', 'HR']\n})\n\n# Create employee salary info\ndf2 = pd.DataFrame({\n    'EmployeeID': [1, 2, 3, 5],\n    'Salary': [8000, 12000, 15000, 10000],\n    'Bonus': [1000, 2000, 3000, 1500]\n})\n\nprint(\"Employee basic info:\")\nprint(df1)\nprint(\"\\nEmployee salary info:\")\nprint(df2)\n\n# Inner join\nprint(\"\\nInner join result:\")\ninner_join = pd.merge(df1, df2, on='EmployeeID', how='inner')\nprint(inner_join)\n\n# Left join\nprint(\"\\nLeft join result:\")\nleft_join = pd.merge(df1, df2, on='EmployeeID', how='left')\nprint(left_join)\n\n# Outer join\nprint(\"\\nOuter join result:\")\nouter_join = pd.merge(df1, df2, on='EmployeeID', how='outer')\nprint(outer_join)\n\n# Join by index\ndf3 = pd.DataFrame({\n    'A': [1, 2, 3],\n    'B': [4, 5, 6]\n}, index=['a', 'b', 'c'])\n\ndf4 = pd.DataFrame({\n    'C': [7, 8, 9],\n    'D': [10, 11, 12]\n}, index=['a', 'b', 'd'])\n\nprint(\"\\nJoin by index:\")\nindex_join = pd.concat([df3, df4], axis=1)\nprint(index_join)"
        }
      ],
      "keyPoints": [
        "Use dropna() to remove missing values, fillna() to fill missing values",
        "groupby() for grouping operations, supports multi-level grouping",
        "pivot_table() creates pivot tables for easy data analysis",
        "merge() combines dataframes with various join types",
        "concat() joins dataframes by rows or columns"
      ]
    }
  },
  "data-cleaning": {
    "zh": {
      "concepts": [
        "数据清洗是数据分析的重要预处理步骤",
        "处理缺失值是数据清洗的核心任务",
        "识别和处理重复数据确保数据质量",
        "异常值检测和处理提高数据可靠性",
        "数据类型转换和格式化统一数据格式"
      ],
      "examples": [
        {
          "title": "缺失值处理",
          "code": "import pandas as pd\nimport numpy as np\n\n# 创建包含缺失值的数据\ndata = {\n    '姓名': ['张三', '李四', None, '王五', '赵六', '孙七'],\n    '年龄': [25, 30, np.nan, 35, 28, None],\n    '工资': [8000, 12000, 15000, None, 10000, 9000],\n    '部门': ['技术', '销售', '技术', '人事', '销售', '技术'],\n    '入职日期': ['2020-01-15', '2019-06-20', None, '2021-03-10', '2020-11-05', '2022-01-01']\n}\ndf = pd.DataFrame(data)\nprint(\"原始数据:\")\nprint(df)\nprint(f\"\\n数据形状: {df.shape}\")\n\n# 检查缺失值\nprint(\"\\n缺失值统计:\")\nmissing_count = df.isnull().sum()\nmissing_percent = (df.isnull().sum() / len(df)) * 100\nmissing_info = pd.DataFrame({\n    '缺失数量': missing_count,\n    '缺失比例(%)': missing_percent.round(2)\n})\nprint(missing_info)\n\n# 方法1: 删除包含缺失值的行\ndf_dropna = df.dropna()\nprint(f\"\\n删除缺失值后形状: {df_dropna.shape}\")\nprint(df_dropna)\n\n# 方法2: 填充缺失值\ndf_filled = df.copy()\n# 用均值填充数值型缺失值\ndf_filled['年龄'] = df_filled['年龄'].fillna(df_filled['年龄'].mean())\ndf_filled['工资'] = df_filled['工资'].fillna(df_filled['工资'].median())\n# 用众数填充分类型缺失值\ndf_filled['姓名'] = df_filled['姓名'].fillna('未知')\ndf_filled['入职日期'] = df_filled['入职日期'].fillna('未知')\n\nprint(\"\\n填充缺失值后:\")\nprint(df_filled)\n\n# 方法3: 前向填充和后向填充\ndf_ffill = df.fillna(method='ffill')  # 前向填充\nprint(\"\\n前向填充:\")\nprint(df_ffill)\n\ndf_bfill = df.fillna(method='bfill')  # 后向填充\nprint(\"\\n后向填充:\")\nprint(df_bfill)"
        },
        {
          "title": "重复数据处理",
          "code": "import pandas as pd\n\n# 创建包含重复数据的数据框\ndata = {\n    '员工ID': [1, 2, 3, 1, 4, 2, 5],\n    '姓名': ['张三', '李四', '王五', '张三', '赵六', '李四', '孙七'],\n    '部门': ['技术', '销售', '技术', '技术', '人事', '销售', '技术'],\n    '工资': [8000, 12000, 15000, 8000, 10000, 12000, 9000]\n}\ndf = pd.DataFrame(data)\nprint(\"原始数据:\")\nprint(df)\n\n# 检查重复行\nprint(f\"\\n总行数: {len(df)}\")\nprint(f\"重复行数: {df.duplicated().sum()}\")\nprint(\"\\n重复行:\")\nprint(df[df.duplicated()])\n\n# 检查特定列的重复值\nprint(\"\\n员工ID重复情况:\")\nid_duplicates = df[df.duplicated(subset=['员工ID'], keep=False)]\nprint(id_duplicates)\n\n# 删除重复行\nprint(\"\\n删除重复行后:\")\ndf_no_duplicates = df.drop_duplicates()\nprint(df_no_duplicates)\nprint(f\"删除后行数: {len(df_no_duplicates)}\")\n\n# 保留第一个重复值，删除后续重复值\ndf_keep_first = df.drop_duplicates(subset=['员工ID'], keep='first')\nprint(\"\\n保留第一个重复值:\")\nprint(df_keep_first)\n\n# 保留最后一个重复值\ndf_keep_last = df.drop_duplicates(subset=['员工ID'], keep='last')\nprint(\"\\n保留最后一个重复值:\")\nprint(df_keep_last)"
        },
        {
          "title": "异常值检测和处理",
          "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 创建包含异常值的数据\nnp.random.seed(42)\ndata = {\n    '员工ID': range(1, 101),\n    '年龄': np.random.normal(30, 5, 100),  # 正常年龄分布\n    '工资': np.random.normal(10000, 2000, 100),  # 正常工资分布\n    '工作年限': np.random.normal(5, 2, 100)  # 正常工作年限\n}\n\n# 添加一些异常值\ndata['年龄'][0] = 150  # 异常年龄\ndata['工资'][1] = 50000  # 异常高工资\ndata['工资'][2] = 1000   # 异常低工资\ndata['工作年限'][3] = -5  # 异常工作年限\n\ndf = pd.DataFrame(data)\nprint(\"包含异常值的数据:\")\nprint(df.head(10))\n\n# 使用IQR方法检测异常值\ndef detect_outliers_iqr(data, column):\n    Q1 = data[column].quantile(0.25)\n    Q3 = data[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n    return outliers, lower_bound, upper_bound\n\n# 检测各列的异常值\ncolumns_to_check = ['年龄', '工资', '工作年限']\nfor col in columns_to_check:\n    outliers, lower, upper = detect_outliers_iqr(df, col)\n    print(f\"\\n{col}异常值检测:\")\n    print(f\"正常范围: [{lower:.2f}, {upper:.2f}]\")\n    print(f\"异常值数量: {len(outliers)}\")\n    if len(outliers) > 0:\n        print(\"异常值:\")\n        print(outliers[['员工ID', col]])\n\n# 使用Z-score方法检测异常值\ndef detect_outliers_zscore(data, column, threshold=3):\n    z_scores = np.abs((data[column] - data[column].mean()) / data[column].std())\n    outliers = data[z_scores > threshold]\n    return outliers\n\nprint(\"\\n使用Z-score方法检测异常值:\")\nfor col in columns_to_check:\n    outliers = detect_outliers_zscore(df, col)\n    print(f\"\\n{col} Z-score异常值数量: {len(outliers)}\")\n    if len(outliers) > 0:\n        print(outliers[['员工ID', col]])\n\n# 处理异常值的方法\nprint(\"\\n异常值处理方法:\")\n\n# 方法1: 删除异常值\ndf_no_outliers = df.copy()\nfor col in columns_to_check:\n    outliers, lower, upper = detect_outliers_iqr(df_no_outliers, col)\n    df_no_outliers = df_no_outliers[(df_no_outliers[col] >= lower) & (df_no_outliers[col] <= upper)]\nprint(f\"删除异常值后数据形状: {df_no_outliers.shape}\")\n\n# 方法2: 用中位数替换异常值\ndf_capped = df.copy()\nfor col in columns_to_check:\n    outliers, lower, upper = detect_outliers_iqr(df_capped, col)\n    df_capped.loc[df_capped[col] < lower, col] = df_capped[col].median()\n    df_capped.loc[df_capped[col] > upper, col] = df_capped[col].median()\nprint(f\"\\n用中位数替换异常值后数据形状: {df_capped.shape}\")\nprint(\"替换后的数据统计:\")\nprint(df_capped[columns_to_check].describe())"
        }
      ],
      "keyPoints": [
        "isnull()和notnull()检查缺失值，sum()统计缺失值数量",
        "dropna()删除缺失值，fillna()填充缺失值",
        "duplicated()检测重复值，drop_duplicates()删除重复值",
        "IQR和Z-score方法检测异常值",
        "异常值处理包括删除、替换、截断等方法"
      ]
    },
    "en": {
      "concepts": [
        "Data cleaning is an important preprocessing step in data analysis",
        "Handling missing values is a core task in data cleaning",
        "Identifying and handling duplicate data ensures data quality",
        "Outlier detection and handling improves data reliability",
        "Data type conversion and formatting standardizes data format"
      ],
      "examples": [
        {
          "title": "Missing Value Handling",
          "code": "import pandas as pd\nimport numpy as np\n\n# Create data with missing values\ndata = {\n    'Name': ['John', 'Jane', None, 'Bob', 'Alice', 'Charlie'],\n    'Age': [25, 30, np.nan, 35, 28, None],\n    'Salary': [8000, 12000, 15000, None, 10000, 9000],\n    'Department': ['IT', 'Sales', 'IT', 'HR', 'Sales', 'IT'],\n    'HireDate': ['2020-01-15', '2019-06-20', None, '2021-03-10', '2020-11-05', '2022-01-01']\n}\ndf = pd.DataFrame(data)\nprint(\"Original data:\")\nprint(df)\nprint(f\"\\nData shape: {df.shape}\")\n\n# Check missing values\nprint(\"\\nMissing values statistics:\")\nmissing_count = df.isnull().sum()\nmissing_percent = (df.isnull().sum() / len(df)) * 100\nmissing_info = pd.DataFrame({\n    'Missing Count': missing_count,\n    'Missing Percentage(%)': missing_percent.round(2)\n})\nprint(missing_info)\n\n# Method 1: Drop rows with missing values\ndf_dropna = df.dropna()\nprint(f\"\\nShape after dropping missing values: {df_dropna.shape}\")\nprint(df_dropna)\n\n# Method 2: Fill missing values\ndf_filled = df.copy()\n# Fill numeric missing values with mean\ndf_filled['Age'] = df_filled['Age'].fillna(df_filled['Age'].mean())\ndf_filled['Salary'] = df_filled['Salary'].fillna(df_filled['Salary'].median())\n# Fill categorical missing values with mode\ndf_filled['Name'] = df_filled['Name'].fillna('Unknown')\ndf_filled['HireDate'] = df_filled['HireDate'].fillna('Unknown')\n\nprint(\"\\nAfter filling missing values:\")\nprint(df_filled)\n\n# Method 3: Forward and backward fill\ndf_ffill = df.fillna(method='ffill')  # Forward fill\nprint(\"\\nForward fill:\")\nprint(df_ffill)\n\ndf_bfill = df.fillna(method='bfill')  # Backward fill\nprint(\"\\nBackward fill:\")\nprint(df_bfill)"
        },
        {
          "title": "Duplicate Data Handling",
          "code": "import pandas as pd\n\n# Create dataframe with duplicate data\ndata = {\n    'EmployeeID': [1, 2, 3, 1, 4, 2, 5],\n    'Name': ['John', 'Jane', 'Bob', 'John', 'Alice', 'Jane', 'Charlie'],\n    'Department': ['IT', 'Sales', 'IT', 'IT', 'HR', 'Sales', 'IT'],\n    'Salary': [8000, 12000, 15000, 8000, 10000, 12000, 9000]\n}\ndf = pd.DataFrame(data)\nprint(\"Original data:\")\nprint(df)\n\n# Check duplicate rows\nprint(f\"\\nTotal rows: {len(df)}\")\nprint(f\"Duplicate rows: {df.duplicated().sum()}\")\nprint(\"\\nDuplicate rows:\")\nprint(df[df.duplicated()])\n\n# Check duplicates in specific columns\nprint(\"\\nEmployeeID duplicates:\")\nid_duplicates = df[df.duplicated(subset=['EmployeeID'], keep=False)]\nprint(id_duplicates)\n\n# Remove duplicate rows\nprint(\"\\nAfter removing duplicates:\")\ndf_no_duplicates = df.drop_duplicates()\nprint(df_no_duplicates)\nprint(f\"Rows after removal: {len(df_no_duplicates)}\")\n\n# Keep first duplicate, remove subsequent duplicates\ndf_keep_first = df.drop_duplicates(subset=['EmployeeID'], keep='first')\nprint(\"\\nKeep first duplicate:\")\nprint(df_keep_first)\n\n# Keep last duplicate\ndf_keep_last = df.drop_duplicates(subset=['EmployeeID'], keep='last')\nprint(\"\\nKeep last duplicate:\")\nprint(df_keep_last)"
        },
        {
          "title": "Outlier Detection and Handling",
          "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create data with outliers\nnp.random.seed(42)\ndata = {\n    'EmployeeID': range(1, 101),\n    'Age': np.random.normal(30, 5, 100),  # Normal age distribution\n    'Salary': np.random.normal(10000, 2000, 100),  # Normal salary distribution\n    'Experience': np.random.normal(5, 2, 100)  # Normal experience\n}\n\n# Add some outliers\ndata['Age'][0] = 150  # Outlier age\ndata['Salary'][1] = 50000  # Outlier high salary\ndata['Salary'][2] = 1000   # Outlier low salary\ndata['Experience'][3] = -5  # Outlier experience\n\ndf = pd.DataFrame(data)\nprint(\"Data with outliers:\")\nprint(df.head(10))\n\n# Use IQR method to detect outliers\ndef detect_outliers_iqr(data, column):\n    Q1 = data[column].quantile(0.25)\n    Q3 = data[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n    return outliers, lower_bound, upper_bound\n\n# Detect outliers in each column\ncolumns_to_check = ['Age', 'Salary', 'Experience']\nfor col in columns_to_check:\n    outliers, lower, upper = detect_outliers_iqr(df, col)\n    print(f\"\\n{col} outlier detection:\")\n    print(f\"Normal range: [{lower:.2f}, {upper:.2f}]\")\n    print(f\"Number of outliers: {len(outliers)}\")\n    if len(outliers) > 0:\n        print(\"Outliers:\")\n        print(outliers[['EmployeeID', col]])\n\n# Use Z-score method to detect outliers\ndef detect_outliers_zscore(data, column, threshold=3):\n    z_scores = np.abs((data[column] - data[column].mean()) / data[column].std())\n    outliers = data[z_scores > threshold]\n    return outliers\n\nprint(\"\\nUsing Z-score method to detect outliers:\")\nfor col in columns_to_check:\n    outliers = detect_outliers_zscore(df, col)\n    print(f\"\\n{col} Z-score outliers: {len(outliers)}\")\n    if len(outliers) > 0:\n        print(outliers[['EmployeeID', col]])\n\n# Methods to handle outliers\nprint(\"\\nOutlier handling methods:\")\n\n# Method 1: Remove outliers\ndf_no_outliers = df.copy()\nfor col in columns_to_check:\n    outliers, lower, upper = detect_outliers_iqr(df_no_outliers, col)\n    df_no_outliers = df_no_outliers[(df_no_outliers[col] >= lower) & (df_no_outliers[col] <= upper)]\nprint(f\"Data shape after removing outliers: {df_no_outliers.shape}\")\n\n# Method 2: Replace outliers with median\ndf_capped = df.copy()\nfor col in columns_to_check:\n    outliers, lower, upper = detect_outliers_iqr(df_capped, col)\n    df_capped.loc[df_capped[col] < lower, col] = df_capped[col].median()\n    df_capped.loc[df_capped[col] > upper, col] = df_capped[col].median()\nprint(f\"\\nData shape after replacing outliers with median: {df_capped.shape}\")\nprint(\"Statistics after replacement:\")\nprint(df_capped[columns_to_check].describe())"
        }
      ],
      "keyPoints": [
        "isnull() and notnull() check missing values, sum() counts missing values",
        "dropna() removes missing values, fillna() fills missing values",
        "duplicated() detects duplicates, drop_duplicates() removes duplicates",
        "IQR and Z-score methods detect outliers",
        "Outlier handling includes removal, replacement, and capping methods"
      ]
    }
  }
}
